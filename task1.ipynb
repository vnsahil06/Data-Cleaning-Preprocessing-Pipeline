{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AdNeevxR5Fhb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    'Employee_ID': [101, 102, 103, 104, 102, 105, 106],\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Bob', 'Eve', np.nan],\n",
        "    'Join_Date': ['2023-01-15', '2023/02/20', '15-03-2023', '2023-04-10', '2023/02/20', '2023-05-05', '2023-06-01'],\n",
        "    'Salary': ['50000', '$60,000', '70000', np.nan, '$60,000', '85000', '90000'],\n",
        "    'Department': ['HR', 'IT', 'Finance', 'IT', 'IT', 'hr', 'Finance']\n",
        "}\n",
        "df_raw = pd.DataFrame(data)\n",
        "df_raw.to_csv('messy_employee_data.csv', index=False)\n",
        "print(\" Created 'messy_employee_data.csv' successfully.\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77v753yd6CzX",
        "outputId": "435463d2-0f35-48d2-b0a6-21bb1d8b6fe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Created 'messy_employee_data.csv' successfully.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_data_pipeline(file_path):\n",
        "    print(\"--- Starting Data Cleaning Pipeline ---\")\n",
        "    df = pd.read_csv(file_path)\n",
        "    print(f\"Original Data Shape: {df.shape}\")"
      ],
      "metadata": {
        "id": "4LWoUQgY7v4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7769be52",
        "outputId": "2c7e42de-0eaf-4ed2-d957-dc3038f2f5e7"
      },
      "source": [
        "def clean_data_pipeline(file_path):\n",
        "    print(\"--- Starting Data Cleaning Pipeline ---\")\n",
        "    df = pd.read_csv(file_path)\n",
        "    print(f\"Original Data Shape: {df.shape}\")\n",
        "    # Removed the recursive call: clean_data_pipeline('messy_employee_data.csv')\n",
        "    df = df.drop_duplicates()\n",
        "    print(\"-> Duplicates removed.\")\n",
        "\n",
        "\n",
        "    df = df.dropna(subset=['Name'])\n",
        "\n",
        "    df['Salary'] = df['Salary'].astype(str).str.replace(r'[$,]', '', regex=True)\n",
        "    df['Salary'] = pd.to_numeric(df['Salary'], errors='coerce')\n",
        "\n",
        "\n",
        "    median_salary = df['Salary'].median()\n",
        "    df['Salary'] = df['Salary'].fillna(median_salary)\n",
        "    print(\"-> Missing values handled and Salary formatted.\")\n",
        "\n",
        "\n",
        "    df['Department'] = df['Department'].str.upper()\n",
        "    print(\"-> Text capitalization standardized.\")\n",
        "\n",
        "\n",
        "    df['Join_Date'] = pd.to_datetime(df['Join_Date'], errors='coerce', dayfirst=False)\n",
        "    print(\"-> Dates standardized.\")\n",
        "\n",
        "\n",
        "    print(f\"Final Data Shape: {df.shape}\")\n",
        "    return df\n",
        "\n",
        "\n",
        "df_cleaned = clean_data_pipeline('messy_employee_data.csv')\n",
        "\n",
        "print(\"\\n--- Final Cleaned Data Preview ---\")\n",
        "print(df_cleaned)\n",
        "\n",
        "df_cleaned.to_csv('cleaned_employee_data.csv', index=False)\n",
        "print(\"\\n Cleaned dataset saved as 'cleaned_employee_data.csv'\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Data Cleaning Pipeline ---\n",
            "Original Data Shape: (7, 5)\n",
            "-> Duplicates removed.\n",
            "-> Missing values handled and Salary formatted.\n",
            "-> Text capitalization standardized.\n",
            "-> Dates standardized.\n",
            "Final Data Shape: (5, 5)\n",
            "\n",
            "--- Final Cleaned Data Preview ---\n",
            "   Employee_ID     Name  Join_Date   Salary Department\n",
            "0          101    Alice 2023-01-15  50000.0         HR\n",
            "1          102      Bob        NaT  60000.0         IT\n",
            "2          103  Charlie        NaT  70000.0    FINANCE\n",
            "3          104    David 2023-04-10  65000.0         IT\n",
            "5          105      Eve 2023-05-05  85000.0         HR\n",
            "\n",
            " Cleaned dataset saved as 'cleaned_employee_data.csv'\n"
          ]
        }
      ]
    }
  ]
}